{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "dataset = pd.read_csv('odataset.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    year  month  day  offset  meat  bread  onion  eggs  milk\n",
      "0   2019      8   24       1     1      0      0     0     0\n",
      "1   2019      8   25       2     1      1      1     1     1\n",
      "2   2019      8   26       3     0      0      0     0     0\n",
      "3   2019      8   27       4     0      1      0     0     0\n",
      "4   2019      8   28       5     0      0      0     0     0\n",
      "..   ...    ...  ...     ...   ...    ...    ...   ...   ...\n",
      "94  2019     11   26      95     0      0      0     0     0\n",
      "95  2019     11   27      96     0      0      0     0     0\n",
      "96  2019     11   28      97     0      0      0     0     0\n",
      "97  2019     11   29      98     0      0      0     0     0\n",
      "98  2019     11   30      99     0      0      0     0     0\n",
      "\n",
      "[99 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "eggs = dataset[[\"eggs\"]].values\n",
    "milks = dataset[[\"milk\"]].values\n",
    "bread = dataset[[\"bread\"]].values\n",
    "onions   = dataset[[\"onion\"]].values\n",
    "meat = dataset[[\"meat\"]].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = []\n",
    "countW = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "for egg in eggs:\n",
    "    \n",
    "    countW = countW+1\n",
    "    w.append(countW)\n",
    "    if egg != 0:\n",
    "        countW = 0\n",
    "dataset[\"eggs_w\"] = w\n",
    "        \n",
    "w = []\n",
    "countW = 0\n",
    "\n",
    "for milk in milks:\n",
    "    \n",
    "    countW = countW+1\n",
    "    w.append(countW)\n",
    "    if milk != 0:\n",
    "        countW = 0\n",
    "\n",
    "dataset[\"milk_w\"] = w        \n",
    "\n",
    "w = []\n",
    "countW = 0\n",
    "        \n",
    "for b in bread:\n",
    "    \n",
    "    countW = countW+1\n",
    "    w.append(countW)\n",
    "    if b != 0:\n",
    "        countW =0\n",
    "\n",
    "dataset[\"bread_w\"] = w\n",
    "\n",
    "w = []\n",
    "countW = 0\n",
    "        \n",
    "for onion in onions:\n",
    "    \n",
    "    countW = countW+1\n",
    "    w.append(countW)\n",
    "    if onion != 0:\n",
    "        countW = 0\n",
    "dataset[\"onion_w\"] = w\n",
    "\n",
    "w = []\n",
    "countW = 0\n",
    "        \n",
    "for m in meat:\n",
    "    \n",
    "    countW = countW+1\n",
    "    w.append(countW)\n",
    "    if m != 0:\n",
    "        countW =0\n",
    "        \n",
    "dataset[\"meat_w\"] = w\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "emptyIndex = []\n",
    "index = 0\n",
    "for row in dataset.iloc[:, 4:9].values:\n",
    "    if all(r == 0 for r in row):\n",
    "        emptyIndex.append(index)\n",
    "    index = index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = dataset.drop(emptyIndex, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n",
      "    year  month  day  offset  meat  bread  onion  eggs  milk  eggs_w  milk_w  \\\n",
      "0   2019      8   24       1     1      0      0     0     0       1       1   \n",
      "1   2019      8   25       2     1      1      1     1     1       2       2   \n",
      "3   2019      8   27       4     0      1      0     0     0       2       2   \n",
      "5   2019      8   29       6     1      1      1     1     1       4       4   \n",
      "8   2019      9    1       9     1      1      0     0     0       3       3   \n",
      "11  2019      9    4      12     0      1      0     1     1       6       6   \n",
      "13  2019      9    6      14     0      1      0     1     0       2       2   \n",
      "21  2019      9   14      22     0      0      0     1     1       8      10   \n",
      "22  2019      9   15      23     1      1      1     0     0       1       1   \n",
      "27  2019      9   20      28     0      1      1     1     1       6       6   \n",
      "31  2019      9   24      32     0      1      1     1     1       4       4   \n",
      "35  2019      9   28      36     0      0      1     0     0       4       4   \n",
      "36  2019      9   29      37     0      0      0     1     1       5       5   \n",
      "39  2019     10    2      40     0      1      1     1     1       3       3   \n",
      "43  2019     10    6      44     0      1      0     1     0       4       4   \n",
      "45  2019     10    8      46     0      0      1     0     1       2       6   \n",
      "49  2019     10   12      50     1      1      0     1     1       6       4   \n",
      "50  2019     10   13      51     0      0      1     0     0       1       1   \n",
      "53  2019     10   16      54     0      0      0     0     1       4       4   \n",
      "55  2019     10   18      56     0      0      1     1     0       6       2   \n",
      "62  2019     10   25      63     0      1      1     1     1       7       9   \n",
      "67  2019     10   30      68     0      1      0     0     0       5       5   \n",
      "68  2019     10   31      69     0      0      1     0     0       6       6   \n",
      "69  2019     11    1      70     0      0      0     1     1       7       7   \n",
      "72  2019     11    4      73     0      0      1     0     0       3       3   \n",
      "77  2019     11    9      78     1      1      1     0     1       8       8   \n",
      "81  2019     11   13      82     0      0      0     0     1      12       4   \n",
      "84  2019     11   16      85     1      1      1     1     1      15       3   \n",
      "85  2019     11   17      86     1      0      0     0     0       1       1   \n",
      "90  2019     11   22      91     0      1      0     0     1       6       6   \n",
      "92  2019     11   24      93     1      1      1     1     1       8       2   \n",
      "\n",
      "    bread_w  onion_w  meat_w  \n",
      "0         1        1       1  \n",
      "1         2        2       1  \n",
      "3         2        2       2  \n",
      "5         2        4       4  \n",
      "8         3        3       3  \n",
      "11        3        6       3  \n",
      "13        2        8       5  \n",
      "21        8       16      13  \n",
      "22        9       17      14  \n",
      "27        5        5       5  \n",
      "31        4        4       9  \n",
      "35        4        4      13  \n",
      "36        5        1      14  \n",
      "39        8        4      17  \n",
      "43        4        4      21  \n",
      "45        2        6      23  \n",
      "49        6        4      27  \n",
      "50        1        5       1  \n",
      "53        4        3       4  \n",
      "55        6        5       6  \n",
      "62       13        7      13  \n",
      "67        5        5      18  \n",
      "68        1        6      19  \n",
      "69        2        1      20  \n",
      "72        5        4      23  \n",
      "77       10        5      28  \n",
      "81        4        4       4  \n",
      "84        7        7       7  \n",
      "85        1        1       1  \n",
      "90        6        6       5  \n",
      "92        2        8       7  \n"
     ]
    }
   ],
   "source": [
    "print(len(dd))\n",
    "print(dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "milk_w    3.555556\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "y_train = dataset[[\"milk\"]]\n",
    "X_train = dataset[[\"milk_w\"]]\n",
    "\n",
    "\n",
    "X_test = np.arange( (X_train.iloc[-1:,-1].values + 1), X_train.iloc[-1:,-1].values + 7, 1)\n",
    "X_test = X_test.reshape(-1,1)\n",
    "\n",
    "mean = np.mean(X_train)\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "milk_w    3.555556\n",
      "dtype: float64\n",
      "[[ 7]\n",
      " [ 8]\n",
      " [ 9]\n",
      " [10]\n",
      " [11]\n",
      " [12]]\n"
     ]
    }
   ],
   "source": [
    "print(mean)\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yrtie\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\yrtie\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# Fitting Logistic Regression to the Training set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "    \n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7]\n",
      " [ 8]\n",
      " [ 9]\n",
      " [10]\n",
      " [11]\n",
      " [12]]\n",
      "[0 0 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)\n",
    "print(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7  8  9 10 11 12]]\n",
      "[0 0 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(X_test.reshape(1,-1))\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 1 1 1]\n",
      "[[ 7]\n",
      " [ 8]\n",
      " [ 9]\n",
      " [10]\n",
      " [11]\n",
      " [12]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yrtie\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# Fitting Naive Bayes to the Training set\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "    \n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(y_pred)\n",
    "print(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Decision Tree Classification to the Training set\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier = DecisionTreeClassifier(criterion = 'entropy')\n",
    "classifier.fit(X_train, y_train)\n",
    "    \n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7]\n",
      " [ 8]\n",
      " [ 9]\n",
      " [10]\n",
      " [11]\n",
      " [12]]\n",
      "[0 0 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yrtie\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", input_dim=1, units=2, kernel_initializer=\"uniform\")`\n",
      "  del sys.path[0]\n",
      "C:\\Users\\yrtie\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=1, kernel_initializer=\"uniform\")`\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\yrtie\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "C:\\Users\\yrtie\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.6919 - accuracy: 0.7374\n",
      "Epoch 2/100\n",
      "99/99 [==============================] - 0s 101us/step - loss: 0.6889 - accuracy: 0.8182\n",
      "Epoch 3/100\n",
      "99/99 [==============================] - 0s 158us/step - loss: 0.6859 - accuracy: 0.8182\n",
      "Epoch 4/100\n",
      "99/99 [==============================] - 0s 157us/step - loss: 0.6831 - accuracy: 0.8182\n",
      "Epoch 5/100\n",
      "99/99 [==============================] - 0s 158us/step - loss: 0.6803 - accuracy: 0.8182\n",
      "Epoch 6/100\n",
      "99/99 [==============================] - 0s 158us/step - loss: 0.6773 - accuracy: 0.8182\n",
      "Epoch 7/100\n",
      "99/99 [==============================] - 0s 158us/step - loss: 0.6747 - accuracy: 0.8182\n",
      "Epoch 8/100\n",
      "99/99 [==============================] - 0s 66us/step - loss: 0.6717 - accuracy: 0.8182\n",
      "Epoch 9/100\n",
      "99/99 [==============================] - 0s 157us/step - loss: 0.6692 - accuracy: 0.8182\n",
      "Epoch 10/100\n",
      "99/99 [==============================] - 0s 158us/step - loss: 0.6665 - accuracy: 0.8182\n",
      "Epoch 11/100\n",
      "99/99 [==============================] - 0s 158us/step - loss: 0.6637 - accuracy: 0.8182\n",
      "Epoch 12/100\n",
      "99/99 [==============================] - 0s 158us/step - loss: 0.6611 - accuracy: 0.8182\n",
      "Epoch 13/100\n",
      "99/99 [==============================] - 0s 235us/step - loss: 0.6586 - accuracy: 0.8182\n",
      "Epoch 14/100\n",
      "99/99 [==============================] - 0s 158us/step - loss: 0.6559 - accuracy: 0.8182\n",
      "Epoch 15/100\n",
      "99/99 [==============================] - 0s 316us/step - loss: 0.6534 - accuracy: 0.8182\n",
      "Epoch 16/100\n",
      "99/99 [==============================] - 0s 158us/step - loss: 0.6510 - accuracy: 0.8182\n",
      "Epoch 17/100\n",
      "99/99 [==============================] - 0s 157us/step - loss: 0.6486 - accuracy: 0.8182\n",
      "Epoch 18/100\n",
      "99/99 [==============================] - 0s 213us/step - loss: 0.6460 - accuracy: 0.8182\n",
      "Epoch 19/100\n",
      "99/99 [==============================] - 0s 170us/step - loss: 0.6436 - accuracy: 0.8182\n",
      "Epoch 20/100\n",
      "99/99 [==============================] - 0s 158us/step - loss: 0.6412 - accuracy: 0.8182\n",
      "Epoch 21/100\n",
      "99/99 [==============================] - 0s 316us/step - loss: 0.6388 - accuracy: 0.8182\n",
      "Epoch 22/100\n",
      "99/99 [==============================] - 0s 157us/step - loss: 0.6365 - accuracy: 0.8182\n",
      "Epoch 23/100\n",
      "99/99 [==============================] - 0s 209us/step - loss: 0.6343 - accuracy: 0.8182\n",
      "Epoch 24/100\n",
      "99/99 [==============================] - 0s 158us/step - loss: 0.6318 - accuracy: 0.8182\n",
      "Epoch 25/100\n",
      "99/99 [==============================] - 0s 316us/step - loss: 0.6297 - accuracy: 0.8182\n",
      "Epoch 26/100\n",
      "99/99 [==============================] - 0s 158us/step - loss: 0.6274 - accuracy: 0.8182\n",
      "Epoch 27/100\n",
      "99/99 [==============================] - 0s 258us/step - loss: 0.6253 - accuracy: 0.8182\n",
      "Epoch 28/100\n",
      "99/99 [==============================] - 0s 101us/step - loss: 0.6230 - accuracy: 0.8182\n",
      "Epoch 29/100\n",
      "99/99 [==============================] - 0s 158us/step - loss: 0.6210 - accuracy: 0.8182\n",
      "Epoch 30/100\n",
      "99/99 [==============================] - 0s 158us/step - loss: 0.6189 - accuracy: 0.8182\n",
      "Epoch 31/100\n",
      "99/99 [==============================] - 0s 316us/step - loss: 0.6168 - accuracy: 0.8182\n",
      "Epoch 32/100\n",
      "99/99 [==============================] - 0s 158us/step - loss: 0.6148 - accuracy: 0.8182\n",
      "Epoch 33/100\n",
      "99/99 [==============================] - 0s 170us/step - loss: 0.6126 - accuracy: 0.8182\n",
      "Epoch 34/100\n",
      "99/99 [==============================] - 0s 51us/step - loss: 0.6108 - accuracy: 0.8182\n",
      "Epoch 35/100\n",
      "99/99 [==============================] - 0s 158us/step - loss: 0.6087 - accuracy: 0.8182\n",
      "Epoch 36/100\n",
      "99/99 [==============================] - 0s 157us/step - loss: 0.6067 - accuracy: 0.8182\n",
      "Epoch 37/100\n",
      "99/99 [==============================] - 0s 158us/step - loss: 0.6049 - accuracy: 0.8182\n",
      "Epoch 38/100\n",
      "99/99 [==============================] - 0s 158us/step - loss: 0.6029 - accuracy: 0.8182\n",
      "Epoch 39/100\n",
      "99/99 [==============================] - 0s 224us/step - loss: 0.6010 - accuracy: 0.8182\n",
      "Epoch 40/100\n",
      "99/99 [==============================] - 0s 158us/step - loss: 0.5993 - accuracy: 0.8182\n",
      "Epoch 41/100\n",
      "99/99 [==============================] - 0s 158us/step - loss: 0.5974 - accuracy: 0.8182\n",
      "Epoch 42/100\n",
      "99/99 [==============================] - 0s 158us/step - loss: 0.5956 - accuracy: 0.8182\n",
      "Epoch 43/100\n",
      "99/99 [==============================] - 0s 158us/step - loss: 0.5938 - accuracy: 0.8182\n",
      "Epoch 44/100\n",
      "99/99 [==============================] - 0s 158us/step - loss: 0.5921 - accuracy: 0.8182\n",
      "Epoch 45/100\n",
      "99/99 [==============================] - 0s 224us/step - loss: 0.5904 - accuracy: 0.8182\n",
      "Epoch 46/100\n",
      "99/99 [==============================] - 0s 158us/step - loss: 0.5885 - accuracy: 0.8182\n",
      "Epoch 47/100\n",
      "99/99 [==============================] - 0s 316us/step - loss: 0.5870 - accuracy: 0.8182\n",
      "Epoch 48/100\n",
      "99/99 [==============================] - 0s 158us/step - loss: 0.5853 - accuracy: 0.8182\n",
      "Epoch 49/100\n",
      "99/99 [==============================] - 0s 157us/step - loss: 0.5837 - accuracy: 0.8182\n",
      "Epoch 50/100\n",
      "99/99 [==============================] - 0s 224us/step - loss: 0.5820 - accuracy: 0.8182\n",
      "Epoch 51/100\n",
      "99/99 [==============================] - 0s 0us/step - loss: 0.5804 - accuracy: 0.8182\n",
      "Epoch 52/100\n",
      "99/99 [==============================] - 0s 157us/step - loss: 0.5789 - accuracy: 0.8182\n",
      "Epoch 53/100\n",
      "99/99 [==============================] - 0s 158us/step - loss: 0.5772 - accuracy: 0.8182\n",
      "Epoch 54/100\n",
      "99/99 [==============================] - 0s 158us/step - loss: 0.5757 - accuracy: 0.8182\n",
      "Epoch 55/100\n",
      "99/99 [==============================] - 0s 158us/step - loss: 0.5742 - accuracy: 0.8182\n",
      "Epoch 56/100\n",
      "99/99 [==============================] - 0s 224us/step - loss: 0.5727 - accuracy: 0.8182\n",
      "Epoch 57/100\n",
      "99/99 [==============================] - 0s 158us/step - loss: 0.5713 - accuracy: 0.8182\n",
      "Epoch 58/100\n",
      "99/99 [==============================] - 0s 158us/step - loss: 0.5698 - accuracy: 0.8182\n",
      "Epoch 59/100\n",
      "99/99 [==============================] - 0s 157us/step - loss: 0.5683 - accuracy: 0.8182\n",
      "Epoch 60/100\n",
      "99/99 [==============================] - 0s 158us/step - loss: 0.5669 - accuracy: 0.8182\n",
      "Epoch 61/100\n",
      "99/99 [==============================] - 0s 158us/step - loss: 0.5655 - accuracy: 0.8182\n",
      "Epoch 62/100\n",
      "99/99 [==============================] - 0s 224us/step - loss: 0.5641 - accuracy: 0.8182\n",
      "Epoch 63/100\n",
      "99/99 [==============================] - 0s 158us/step - loss: 0.5628 - accuracy: 0.8182\n",
      "Epoch 64/100\n",
      "99/99 [==============================] - 0s 158us/step - loss: 0.5613 - accuracy: 0.8182\n",
      "Epoch 65/100\n",
      "99/99 [==============================] - 0s 158us/step - loss: 0.5601 - accuracy: 0.8182\n",
      "Epoch 66/100\n",
      "99/99 [==============================] - 0s 158us/step - loss: 0.5587 - accuracy: 0.8182\n",
      "Epoch 67/100\n",
      "99/99 [==============================] - 0s 157us/step - loss: 0.5576 - accuracy: 0.8182\n",
      "Epoch 68/100\n",
      "99/99 [==============================] - 0s 66us/step - loss: 0.5561 - accuracy: 0.8182\n",
      "Epoch 69/100\n",
      "99/99 [==============================] - 0s 158us/step - loss: 0.5548 - accuracy: 0.8182\n",
      "Epoch 70/100\n",
      "99/99 [==============================] - 0s 158us/step - loss: 0.5536 - accuracy: 0.8182\n",
      "Epoch 71/100\n",
      "99/99 [==============================] - 0s 158us/step - loss: 0.5526 - accuracy: 0.8182\n",
      "Epoch 72/100\n",
      "99/99 [==============================] - 0s 157us/step - loss: 0.5513 - accuracy: 0.8182\n",
      "Epoch 73/100\n",
      "99/99 [==============================] - 0s 158us/step - loss: 0.5500 - accuracy: 0.8182\n",
      "Epoch 74/100\n",
      "99/99 [==============================] - 0s 224us/step - loss: 0.5488 - accuracy: 0.8182\n",
      "Epoch 75/100\n",
      "99/99 [==============================] - 0s 158us/step - loss: 0.5477 - accuracy: 0.8182\n",
      "Epoch 76/100\n",
      "99/99 [==============================] - 0s 158us/step - loss: 0.5467 - accuracy: 0.8182\n",
      "Epoch 77/100\n",
      "99/99 [==============================] - 0s 158us/step - loss: 0.5454 - accuracy: 0.8182\n",
      "Epoch 78/100\n",
      "99/99 [==============================] - 0s 157us/step - loss: 0.5443 - accuracy: 0.8182\n",
      "Epoch 79/100\n",
      "99/99 [==============================] - 0s 158us/step - loss: 0.5433 - accuracy: 0.8182\n",
      "Epoch 80/100\n",
      "99/99 [==============================] - 0s 224us/step - loss: 0.5422 - accuracy: 0.8182\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 0s 158us/step - loss: 0.5410 - accuracy: 0.8182\n",
      "Epoch 82/100\n",
      "99/99 [==============================] - 0s 158us/step - loss: 0.5401 - accuracy: 0.8182\n",
      "Epoch 83/100\n",
      "99/99 [==============================] - 0s 158us/step - loss: 0.5391 - accuracy: 0.8182\n",
      "Epoch 84/100\n",
      "99/99 [==============================] - 0s 158us/step - loss: 0.5380 - accuracy: 0.8182\n",
      "Epoch 85/100\n",
      "99/99 [==============================] - 0s 157us/step - loss: 0.5369 - accuracy: 0.8182\n",
      "Epoch 86/100\n",
      "99/99 [==============================] - 0s 0us/step - loss: 0.5361 - accuracy: 0.8182\n",
      "Epoch 87/100\n",
      "99/99 [==============================] - 0s 66us/step - loss: 0.5350 - accuracy: 0.8182\n",
      "Epoch 88/100\n",
      "99/99 [==============================] - 0s 158us/step - loss: 0.5340 - accuracy: 0.8182\n",
      "Epoch 89/100\n",
      "99/99 [==============================] - 0s 158us/step - loss: 0.5330 - accuracy: 0.8182\n",
      "Epoch 90/100\n",
      "99/99 [==============================] - 0s 158us/step - loss: 0.5322 - accuracy: 0.8182\n",
      "Epoch 91/100\n",
      "99/99 [==============================] - 0s 157us/step - loss: 0.5312 - accuracy: 0.8182\n",
      "Epoch 92/100\n",
      "99/99 [==============================] - 0s 158us/step - loss: 0.5302 - accuracy: 0.8182\n",
      "Epoch 93/100\n",
      "99/99 [==============================] - 0s 158us/step - loss: 0.5294 - accuracy: 0.8182\n",
      "Epoch 94/100\n",
      "99/99 [==============================] - 0s 66us/step - loss: 0.5285 - accuracy: 0.8182\n",
      "Epoch 95/100\n",
      "99/99 [==============================] - 0s 158us/step - loss: 0.5277 - accuracy: 0.8182\n",
      "Epoch 96/100\n",
      "99/99 [==============================] - 0s 157us/step - loss: 0.5267 - accuracy: 0.8182\n",
      "Epoch 97/100\n",
      "99/99 [==============================] - 0s 0us/step - loss: 0.5259 - accuracy: 0.8182\n",
      "Epoch 98/100\n",
      "99/99 [==============================] - 0s 158us/step - loss: 0.5251 - accuracy: 0.8182\n",
      "Epoch 99/100\n",
      "99/99 [==============================] - 0s 0us/step - loss: 0.5242 - accuracy: 0.8182\n",
      "Epoch 100/100\n",
      "99/99 [==============================] - 0s 66us/step - loss: 0.5234 - accuracy: 0.8182\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "# Initialising the ANN\n",
    "classifier = Sequential()\n",
    "    \n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(output_dim = 2, init = 'uniform', activation = 'sigmoid', input_dim = 1))\n",
    "\n",
    "classifier.add(Dense(output_dim = 1, init = 'uniform', activation = 'relu'))\n",
    "\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid'))\n",
    "    \n",
    "# Compiling the ANN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "# Fitting the ANN to the Training set\n",
    "classifier.fit(X_train, y_train, batch_size = 10, nb_epoch = 100)\n",
    "\n",
    "# Part 3 - Making the predictions and evaluating the model\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
